{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data/\n",
    "    piece_identite/\n",
    "        id1.jpg\n",
    "        id2.jpg\n",
    "        ...\n",
    "    diplome/\n",
    "        diploma1.jpg\n",
    "        diploma2.jpg\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bcc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Chemins des répertoires de données\n",
    "train_dir = 'data/train'\n",
    "validation_dir = 'data/validation'\n",
    "\n",
    "# Prétraitement des images et augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Charger le modèle MobileNetV2 pré-entraîné sans la top layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Ajouter des couches de classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Définir le modèle complet\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "# Sauvegarder le modèle entraîné\n",
    "model.save('document_classifier_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b890617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Charger le modèle\n",
    "model = load_model('document_classifier_model.h5')\n",
    "\n",
    "# Charger et prétraiter une nouvelle image\n",
    "img_path = 'path_to_new_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Prédire la catégorie de la nouvelle image\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = 'piece_identite' if prediction[0] < 0.5 else 'diplome'\n",
    "print(predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Exemple de données\n",
    "documents = [\n",
    "    \"Diplôme en informatique de l'université X\",\n",
    "    \"Carte d'identité de la République\",\n",
    "    \"Support de cours de mathématiques\",\n",
    "    # ...\n",
    "]\n",
    "labels = [\"Diplôme\", \"Pièce d'identité\", \"Support de cours\"]\n",
    "\n",
    "# Prétraitement et séparation des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline TF-IDF et SVM\n",
    "pipeline = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
    "\n",
    "# Entraînement du modèle\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification de Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1bc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Exemple de données d'entraînement (à remplacer par vos données réelles)\n",
    "documents = [\n",
    "    \"Piece d'identite de Jean\",\n",
    "    \"Diplome de Marie\",\n",
    "    \"Support de cours de Maths\",\n",
    "    \"Piece d'identite de Paul\",\n",
    "    \"Diplome de Sophie\",\n",
    "    \"Support de cours de Physique\"\n",
    "]\n",
    "labels = [\n",
    "    \"Piece d'identite\",\n",
    "    \"Diplome\",\n",
    "    \"Support de cours\",\n",
    "    \"Piece d'identite\",\n",
    "    \"Diplome\",\n",
    "    \"Support de cours\"\n",
    "]\n",
    "\n",
    "# Conversion des documents en vecteurs TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Entraîner un classificateur KNN\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Sauvegarder le modèle et le vectorizer\n",
    "joblib.dump(model, 'knn_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "@app.route('/classify', methods=['POST'])\n",
    "def classify():\n",
    "    document = request.form['document']\n",
    "    \n",
    "    # Charger le modèle et le vectorizer\n",
    "    model = joblib.load('knn_model.pkl')\n",
    "    vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    \n",
    "    # Transformer le document en vecteur TF-IDF\n",
    "    X_new = vectorizer.transform([document])\n",
    "    \n",
    "    # Prédire la catégorie du document\n",
    "    prediction = model.predict(X_new)[0]\n",
    "    \n",
    "    return f'Le document est classé comme: {prediction}'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Exemple de données d'entraînement\n",
    "documents = [\"Document 1\", \"Document 2\", ...]\n",
    "labels = [\"Classe 1\", \"Classe 2\", ...]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un pipeline de prétraitement et de modèle\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer le modèle\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0177281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
